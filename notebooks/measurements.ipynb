{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubix/miniconda3/envs/llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import gradio as gr\n",
    "from TTS.api import TTS\n",
    "os.environ[\"COQUI_TOS_AGREED\"] = \"1\"\n",
    "os.environ[\"PYTHONPATH\"] = \"/usr/lib/python3.10/dist-packages/\"\n",
    "\n",
    "from kitt.core import voices, tts_gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_embedding_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-05-21 14:20:22.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mkitt.core\u001b[0m:\u001b[36mload_tts_pipeline\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mLoading model tts_models/multilingual/multi-dataset/xtts_v2 into device: cuda\u001b[0m\n",
      "/home/ubix/TTS/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.\n",
      "  warnings.warn(\"`gpu` will be deprecated. Please use `tts.to(device)` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorrt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mtts_gradio\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mThe path to glory isn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt paved. Be very careful what you say\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFreeman - Neutral\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeaker_embedding_cache\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kitt/kitt/core/__init__.py:191\u001b[0m, in \u001b[0;36mtts_gradio\u001b[0;34m(text, voice, cache)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tts_pipeline\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tts_pipeline:\n\u001b[0;32m--> 191\u001b[0m     tts_pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mload_tts_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m voice_path \u001b[38;5;241m=\u001b[39m voice_from_text(voice)\n\u001b[1;32m    194\u001b[0m speed \u001b[38;5;241m=\u001b[39m speed_from_text(voice)\n",
      "File \u001b[0;32m~/kitt/kitt/core/__init__.py:60\u001b[0m, in \u001b[0;36mload_tts_pipeline\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m into device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# device = \"mps\"\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m tts_pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mTTS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tts_pipeline\n",
      "File \u001b[0;32m~/TTS/TTS/api.py:74\u001b[0m, in \u001b[0;36mTTS.__init__\u001b[0;34m(self, model_name, model_path, config_path, vocoder_path, vocoder_config_path, progress_bar, gpu)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(model_name) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtts_models\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_name:\n\u001b[0;32m---> 74\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_tts_model_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvoice_conversion_models\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_name:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_vc_model_by_name(model_name, gpu)\n",
      "File \u001b[0;32m~/TTS/TTS/api.py:177\u001b[0m, in \u001b[0;36mTTS.load_tts_model_by_name\u001b[0;34m(self, model_name, gpu)\u001b[0m\n\u001b[1;32m    171\u001b[0m model_path, config_path, vocoder_path, vocoder_config_path, model_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_model_by_name(\n\u001b[1;32m    172\u001b[0m     model_name\n\u001b[1;32m    173\u001b[0m )\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# init synthesizer\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m# None values are fetch from the model\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msynthesizer \u001b[38;5;241m=\u001b[39m \u001b[43mSynthesizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtts_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtts_config_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtts_speakers_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtts_languages_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocoder_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocoder_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocoder_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocoder_config_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/TTS/TTS/utils/synthesizer.py:109\u001b[0m, in \u001b[0;36mSynthesizer.__init__\u001b[0;34m(self, tts_checkpoint, tts_config_path, tts_speakers_file, tts_languages_file, vocoder_checkpoint, vocoder_config, encoder_checkpoint, encoder_config, vc_checkpoint, vc_config, model_dir, voice_dir, use_cuda)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_sample_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts_config\u001b[38;5;241m.\u001b[39maudio[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_tts_from_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cuda\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_sample_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts_config\u001b[38;5;241m.\u001b[39maudio[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_sample_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/TTS/TTS/utils/synthesizer.py:161\u001b[0m, in \u001b[0;36mSynthesizer._load_tts_from_dir\u001b[0;34m(self, model_dir, use_cuda)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_tts_from_dir\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_dir: \u001b[38;5;28mstr\u001b[39m, use_cuda: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load the TTS model from a directory.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    We assume the model knows how to load itself from the directory and there is a config.json file in the directory.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[43mload_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts_config \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtts_model \u001b[38;5;241m=\u001b[39m setup_tts_model(config)\n",
      "File \u001b[0;32m~/TTS/TTS/config/__init__.py:97\u001b[0m, in \u001b[0;36mload_config\u001b[0;34m(config_path)\u001b[0m\n\u001b[1;32m     95\u001b[0m config_dict\u001b[38;5;241m.\u001b[39mupdate(data)\n\u001b[1;32m     96\u001b[0m model_name \u001b[38;5;241m=\u001b[39m _process_model_name(config_dict)\n\u001b[0;32m---> 97\u001b[0m config_class \u001b[38;5;241m=\u001b[39m \u001b[43mregister_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m config \u001b[38;5;241m=\u001b[39m config_class()\n\u001b[1;32m     99\u001b[0m config\u001b[38;5;241m.\u001b[39mfrom_dict(config_dict)\n",
      "File \u001b[0;32m~/TTS/TTS/config/__init__.py:40\u001b[0m, in \u001b[0;36mregister_config\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# TODO: fix this\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxtts\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mTTS\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfigs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxtts_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XttsConfig\n\u001b[1;32m     42\u001b[0m     config_class \u001b[38;5;241m=\u001b[39m XttsConfig\n\u001b[1;32m     43\u001b[0m paths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTTS.tts.configs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTTS.vocoder.configs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTTS.encoder.configs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTTS.vc.configs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/TTS/TTS/tts/configs/xtts_config.py:5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mTTS\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfigs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshared_configs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseTTSConfig\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mTTS\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxtts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XttsArgs, XttsAudioConfig\n\u001b[1;32m      8\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mXttsConfig\u001b[39;00m(BaseTTSConfig):\n\u001b[1;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Defines parameters for XTTS TTS model.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m        >>> config = XttsConfig()\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/TTS/TTS/tts/models/xtts.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mTTS\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_tts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseTTS\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mTTS\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_fsspec\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch2trt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m torch2trt, TRTModule\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorrt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtrt\u001b[39;00m\n\u001b[1;32m     23\u001b[0m init_stream_support()\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.10/site-packages/torch2trt-0.5.0-py3.10.egg/torch2trt/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch2trt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconverters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorrt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtrt\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.10/site-packages/torch2trt-0.5.0-py3.10.egg/torch2trt/torch2trt.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorrt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtrt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorrt'"
     ]
    }
   ],
   "source": [
    "out = tts_gradio(\"The path to glory isn't paved. Be very careful what you say\", \"Freeman - Neutral\", speaker_embedding_cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubix/miniconda3/envs/llm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "transcriber = pipeline(\n",
    "    \"automatic-speech-recognition\", model=\"openai/whisper-base.en\", device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22050,\n",
       " array([-0.00043467, -0.00379933, -0.00812101, ...,  0.        ,\n",
       "         0.        ,  0.        ]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr, y = out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391 ms ± 39 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit transcriber({\"sampling_rate\": sr, \"raw\": y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' The path to glory is in paves. Be very careful what you say.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.tools.base import StructuredTool\n",
    "\n",
    "\n",
    "from kitt.core.model import process_query\n",
    "from kitt.skills import (\n",
    "    get_weather,\n",
    "    find_route,\n",
    "    get_forecast,\n",
    "    vehicle_status as vehicle_status_fn,\n",
    "    search_points_of_interests,\n",
    "    search_along_route_w_coordinates,\n",
    "    do_anything_else,\n",
    "    date_time_info,\n",
    "    get_weather_current_location,\n",
    "    code_interpreter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = ChatMessageHistory()\n",
    "tools = [\n",
    "    StructuredTool.from_function(get_weather),\n",
    "    StructuredTool.from_function(find_route),\n",
    "    StructuredTool.from_function(vehicle_status_fn),\n",
    "    StructuredTool.from_function(search_points_of_interests),\n",
    "    # StructuredTool.from_function(search_along_route),\n",
    "    StructuredTool.from_function(date_time_info),\n",
    "    StructuredTool.from_function(get_weather_current_location),\n",
    "    StructuredTool.from_function(code_interpreter),\n",
    "    # StructuredTool.from_function(do_anything_else),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt is:<|im_start|>system\n",
      "You are a function calling AI agent with self-recursion.\n",
      "You can call only one function at a time and analyse data you get from function response.\n",
      "You are provided with function signatures within <tools></tools> XML tags.\n",
      "\n",
      "You may use agentic frameworks for reasoning and planning to help with user query.\n",
      "Please call a function and wait for function results to be provided to you in the next iteration.\n",
      "Don't make assumptions about what values to plug into function arguments.\n",
      "Once you have called a function, results will be fed back to you within <tool_response></tool_response> XML tags.\n",
      "Don't make assumptions about tool results if <tool_response> XML tags are not present since function hasn't been executed yet.\n",
      "Analyze the data once you get the results and call another function.\n",
      "At each iteration please continue adding the your analysis to previous summary.\n",
      "Your final response should directly answer the user query. Don't tell what you are doing, just do it.\n",
      "\n",
      "\n",
      "Here are the available tools:\n",
      "<tools> [{'name': 'get_weather', 'description': 'Get the current weather in a specified location.\\nWhen responding to user, only mention the weather condition, temperature, and the temperature that it feels like, unless the user asks for more information.\\n\\nArgs:\\n    location (string) : Optional. The name of the location, if empty, the vehicle location is used.\\n\\nReturns:\\n    dict: The weather data in the specified location.', 'parameters': {'type': 'object', 'properties': {'location': {'default': '', 'type': 'string'}}, {'name': 'find_route', 'description': 'Get a route to a destination from the current location of the vehicle.\\n\\n    Args:\\n    destination (string): Optional. The destination name.', 'parameters': {'type': 'object', 'properties': {'destination': {}, 'required': ['destination']}, {'name': 'vehicle_status', 'description': 'Get current vehicle status, which includes, location, date, time, destination.\\n    Call this to get the current destination or location of the car/vehicle.\\n    Returns:\\n        dict[str, str]: The vehicle status. For example:\\n        {\\n            \"location\": \"Luxembourg Gare, Luxembourg\",\\n            \"lat\": 49.6000,\\n            \"lon\": 6.1333,\\n            \"date\": \"2025-03-29\",\\n            \"time\": \"08:00:20\",\\n            \"destination\": \"Kirchberg Campus, Kirchberg\"\\n        }', 'parameters': {'type': 'object', 'properties': {}}, {'name': 'search_points_of_interests', 'description': 'Get some of the closest points of interest matching the query.\\n\\nArgs:\\n    search_query (string): Required. Describing the type of point of interest depending on what the user wants to do. Make sure to include the type of POI you are looking for. For example italian restaurant, grocery shop, etc.', 'parameters': {'type': 'object', 'properties': {'search_query': {'default': 'french restaurant'}}, {'name': 'date_time_info', 'description': 'Get the current date and time.', 'parameters': {'type': 'object', 'properties': {}}, {'name': 'get_weather_current_location', 'description': 'Returns the CURRENT weather in current location.\\nWhen responding to user, only mention the weather condition, temperature, and the temperature that it feels like, unless the user asks for more information.\\n\\nReturns:\\n    dict: The weather data in the specified location.', 'parameters': {'type': 'object', 'properties': {}}, {'name': 'code_interpreter', 'description': 'Execute the provided Python code string on the terminal using exec.\\n\\n    The string should contain valid, executable and pure Python code in markdown syntax.\\n    Code should also import any required Python packages.\\n\\n    Args:\\n        code_markdown (str): The Python code with markdown syntax to be executed.\\n            For example: ```python\\n<code-string>\\n```\\n\\n    Returns:\\n        dict | str: A dictionary containing variables declared and values returned by function calls,\\n            or an error message if an exception occurred.\\n\\n    Note:\\n        Use this function with caution, as executing arbitrary code can pose security risks. Use it only for numerical calculations.', 'parameters': {'type': 'object', 'properties': {'code_markdown': {'type': 'string'}, 'required': ['code_markdown']}] </tools>\n",
      "If the provided function signatures doesn't have the function you must call, you may write executable python code in markdown syntax and call code_interpreter() function as follows:\n",
      "<tool_call>\n",
      "{\"arguments\": {\"code_markdown\": <python-code>, \"name\": \"code_interpreter\"}\n",
      "</tool_call>\n",
      "Make sure that the json object above with code markdown block is parseable with json.loads() and the XML block with XML ElementTree.\n",
      "When using tools, ensure to only use the tools provided and not make up any data and do not provide any explanation as to which tool you are using and why.\n",
      "\n",
      "Example 1:\n",
      "User: How is the weather today?\n",
      "Assistant:\n",
      "<tool_call>\n",
      "{\"arguments\": {\"location\": \"\"}, \"name\": \"get_weather\"}\n",
      "</tool_call>\n",
      "\n",
      "Example 2:\n",
      "User: Is there a Spa nearby?\n",
      "Assistant:\n",
      "<tool_call>\n",
      "{\"arguments\": {\"search_query\": \"Spa\"}, \"name\": \"search_points_of_interests\"}\n",
      "</tool_call>\n",
      "\n",
      "Example 3:\n",
      "User: How long will it take to get to the destination?\n",
      "Assistant:\n",
      "<tool_call>\n",
      "{\"arguments\": {\"destination\": \"\"}, \"name\": \"calculate_route\"}\n",
      "\n",
      "When asked for the weather or points of interest, use the appropriate tool with the current location of the car. Unless the user provides a location, then use that location.\n",
      "Always assume user wants to travel by car.\n",
      "\n",
      "Use the following pydantic model json schema for each tool call you will make:\n",
      "{'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}, 'required': ['arguments', 'name'], 'title': 'FunctionCall', 'type': 'object'}\n",
      "\n",
      "At the very first turn you don't have <tool_results> so you shouldn't not make up the results.\n",
      "Please keep a running summary with analysis of previous function results and summaries from previous iterations.\n",
      "Do not stop calling functions until the task has been accomplished or you've reached max iteration of 10.\n",
      "If you plan to continue with analysis, always call another function.\n",
      "For each function call return a valid json object (using doulbe quotes) with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
      "<tool_call>\n",
      "{\"arguments\": <args-dict>, \"name\": <function-name>}\n",
      "</tool_call>\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "Given that:\n",
      "The current location is: Rue Alphonse Weicker, Luxembourg (49.505, 6.28111)\n",
      "The current date and time: 2025-05-06 08:00:00\n",
      "The current destination is: Rue Alphonse Weicker, Luxembourg\n",
      "Answer the following:\n",
      "How is the weather?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "------------------\n",
      "\n"
     ]
    },
    {
     "ename": "ResponseError",
     "evalue": "model 'dolphin-llama3:8b' not found, try pulling it first",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResponseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprocess_query\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHow is the weather?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kitt/kitt/core/model.py:263\u001b[0m, in \u001b[0;36mprocess_query\u001b[0;34m(user_query, history, tools)\u001b[0m\n\u001b[1;32m    261\u001b[0m history\u001b[38;5;241m.\u001b[39madd_message(HumanMessage(content\u001b[38;5;241m=\u001b[39muser_query_status))\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m depth \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m--> 263\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mrun_inference_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema_json\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference step result:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    265\u001b[0m     history\u001b[38;5;241m.\u001b[39madd_message(AIMessage(content\u001b[38;5;241m=\u001b[39mout))\n",
      "File \u001b[0;32m~/kitt/kitt/core/model.py:249\u001b[0m, in \u001b[0;36mrun_inference_step\u001b[0;34m(depth, history, tools, schema_json, dry_run)\u001b[0m\n\u001b[1;32m    247\u001b[0m client \u001b[38;5;241m=\u001b[39m Client(host\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://localhost:11434\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# out = ollama.generate(**data)\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse from model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    251\u001b[0m res \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.10/site-packages/ollama/_client.py:126\u001b[0m, in \u001b[0;36mClient.generate\u001b[0;34m(self, model, prompt, system, template, context, stream, raw, format, images, options, keep_alive)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model:\n\u001b[1;32m    124\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m RequestError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmust provide a model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_stream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api/generate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m  \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemplate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mraw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m_encode_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mformat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moptions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkeep_alive\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m  \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m  \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.10/site-packages/ollama/_client.py:97\u001b[0m, in \u001b[0;36mClient._request_stream\u001b[0;34m(self, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_request_stream\u001b[39m(\n\u001b[1;32m     92\u001b[0m   \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     93\u001b[0m   \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m     94\u001b[0m   stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     95\u001b[0m   \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     96\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Mapping[\u001b[38;5;28mstr\u001b[39m, Any], Iterator[Mapping[\u001b[38;5;28mstr\u001b[39m, Any]]]:\n\u001b[0;32m---> 97\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.10/site-packages/ollama/_client.py:73\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, method, url, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m   response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 73\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mtext, e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[0;31mResponseError\u001b[0m: model 'dolphin-llama3:8b' not found, try pulling it first"
     ]
    }
   ],
   "source": [
    "process_query(\"How is the weather?\", history, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
