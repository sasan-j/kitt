{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#run this cell and then restart execution\n",
        "!pip install accelerate\n",
        "!pip install bitsandbytes\n",
        "!pip install optimum\n",
        "!pip install auto-gptq\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!pip install -U gradio==3.32.0"
      ],
      "metadata": {
        "id": "rd5vZMt_2wrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "oOnNfKjX4IAV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcKbgNj8sLDQ"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "from transformers import AutoModelForCausalLM,AutoTokenizer\n",
        "import torch\n",
        "!pip install transformers huggingface_hub\n",
        "#from huggingface_hub import notebook_login\n",
        "\n",
        "#notebook_login()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mn = 'stabilityai/StableBeluga-7B'\n",
        "#mn = \"TheBloke/Llama-2-7b-Chat-GPTQ\""
      ],
      "metadata": {
        "id": "l3CZ0ImaserU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(mn, device_map=0, load_in_8bit=True)\n",
        "\n",
        "#model = AutoModelForCausalLM.from_pretrained(mn, device_map=0, torch_dtype=torch.float16)"
      ],
      "metadata": {
        "id": "1M3zHAtmwrDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sb_sys = \"### System:\\nYou are a AI assistant in my car, that follows instructions extremely well. Help as much as you can. Answer questions concisely and effectively with the requested information.\\n\\n\"\n"
      ],
      "metadata": {
        "id": "jLyLFoXLJNwW"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen(p, maxlen=15, sample=True):\n",
        "    toks = tokr(p, return_tensors=\"pt\")\n",
        "    res = model.generate(**toks.to(\"cuda\"), max_new_tokens=maxlen, do_sample=sample).to('cpu')\n",
        "    return tokr.batch_decode(res)"
      ],
      "metadata": {
        "id": "ivYhrlgtLDle"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokr = AutoTokenizer.from_pretrained(mn)"
      ],
      "metadata": {
        "id": "lMm24JII4D9F"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to have a prompt corresponding to the specific format required by the fine-tuned model Stable Beluga\n",
        "def mk_prompt(user, syst=sb_sys): return f\"{syst}### User: {user}\\n\\n### Assistant:\\n\""
      ],
      "metadata": {
        "id": "uUizoAiQKvlw"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complete_answer= ''"
      ],
      "metadata": {
        "id": "8cph2QynVyvc"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#attempt to get user location\n",
        "\n",
        "import requests\n",
        "\n",
        "response = requests.get(\"http://ip-api.com/json/\")\n",
        "data = response.json()\n",
        "print(data['city'], data['lat'], data['lon'])\n",
        "city= data['city']\n",
        "lat = data['lat']\n",
        "lon = data['lon']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-KKaqPwXuji",
        "outputId": "73a2206e-efa3-43d3-ec88-5edd911a5771"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Dalles 45.5945 -121.1786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "model_answer= ''\n",
        "general_context= f'I am in my car in {city}. My exact position is latitude {lat}, longitude {lon}. I can move with my car to reach a destination'\n",
        "# Define the initial state with some initial context.\n",
        "initial_state = {'context': general_context}\n",
        "pattern = r\"Assistant:\\\\n(.*?)</s>\"\n",
        "#The api key for weather (and only for weather) is a08df3f6b6264a1facc135137230311"
      ],
      "metadata": {
        "id": "hiNY_Lo3P8jK"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def car_answer_only(complete_answer, general_context):\n",
        "    match = re.search(pattern, complete_answer, re.DOTALL)\n",
        "\n",
        "    if match:\n",
        "        # Extracting the text\n",
        "        model_answer = match.group(1)\n",
        "    else:\n",
        "        model_answer = \"There has been an error with the generated response.\"\n",
        "\n",
        "    general_context +=  model_answer\n",
        "    return (model_answer, general_context)\n",
        "#print(model_answer)"
      ],
      "metadata": {
        "id": "yAJI0WyOLE8G"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def FnAnswer(general_context, ques, state):\n",
        "    # Initialize state if it is None\n",
        "    if state is None:\n",
        "        state = {}\n",
        "        state['context'] = general_context\n",
        "\n",
        "\n",
        "    question=f\"\"\"Answer the question with the help of the provided context.\n",
        "\n",
        "    ## Context\n",
        "\n",
        "    {general_context} .\n",
        "\n",
        "    ## Question\n",
        "\n",
        "    {ques}\"\"\"\n",
        "\n",
        "    complete_answer = str(gen(mk_prompt(question), 300))\n",
        "\n",
        "    model_answer, general_context= car_answer_only(complete_answer, general_context)\n",
        "\n",
        "    state['context'] = state['context'] + \". \" + model_answer\n",
        "\n",
        "\n",
        "    return model_answer, state['context'], state"
      ],
      "metadata": {
        "id": "ViCEgogaENNV"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_context= initial_state['context']\n",
        "# Create the Gradio interface.\n",
        "iface = gr.Interface(\n",
        "    fn=FnAnswer,\n",
        "    inputs=[\n",
        "        gr.Textbox(value=initial_context, visible=False),\n",
        "        gr.Textbox(lines=2, placeholder=\"Type your message here...\"),\n",
        "        gr.State()  # This will keep track of the context state across interactions.\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(),\n",
        "        gr.Textbox(visible=False),\n",
        "        gr.State()\n",
        "    ]\n",
        ")\n",
        "# Launch the interface.\n",
        "iface.launch(debug=True, share=True)\n",
        "#contextual=gr.Textbox(value=general_context, visible=False)\n",
        "#demo = gr.Interface(fn=FnAnswer, inputs=[contextual,\"text\"], outputs=[\"text\", contextual])\n",
        "\n",
        "#demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "Z8t7vK3xKXn_",
        "outputId": "58a5f26a-4637-43e9-8e66-669048962a25"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://35a817dd1b018474f4.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://35a817dd1b018474f4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://35a817dd1b018474f4.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#weather API\n",
        "\n",
        "import requests\n",
        "\n",
        "def get_weather_with_weatherapi(api_key:str, city_name:str):\n",
        "    # The endpoint URL provided by WeatherAPI\n",
        "    url = f\"http://api.weatherapi.com/v1/current.json?key={api_key}&q={city_name}&aqi=no\"\n",
        "\n",
        "    # Make the API request\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        # Parse the JSON response\n",
        "        weather_data = response.json()\n",
        "\n",
        "        # Extracting the necessary pieces of data\n",
        "        location = weather_data['location']['name']\n",
        "        region = weather_data['location']['region']\n",
        "        country = weather_data['location']['country']\n",
        "        time = weather_data['location']['localtime']\n",
        "        temperature_c = weather_data['current']['temp_c']\n",
        "        condition_text = weather_data['current']['condition']['text']\n",
        "        wind_mph = weather_data['current']['wind_mph']\n",
        "        humidity = weather_data['current']['humidity']\n",
        "        feelslike_c = weather_data['current']['feelslike_c']\n",
        "\n",
        "        # Formulate the sentences\n",
        "        weather_sentences = (\n",
        "            f\"The current weather in {location}, {region}, {country} is {condition_text} \"\n",
        "            f\"with a temperature of {temperature_c}°C that feels like {feelslike_c}°C. \"\n",
        "            f\"Humidity is at {humidity}%. \"\n",
        "            f\"Wind speed is {wind_mph} mph.\"\n",
        "            f\"the local time is {time}\"\n",
        "        )\n",
        "        return weather_sentences\n",
        "    else:\n",
        "        # Handle errors\n",
        "        return f\"Failed to get weather data: {response.status_code}, {response.text}\"\n",
        "\n",
        "# Replace 'YOUR_API_KEY' with your actual API key from WeatherAPI and 'CITY_NAME' with your city\n",
        "api_key = 'a08df3f6b6264a1facc135137230311'\n",
        "city_name = 'Las Vegas'\n",
        "weather_info = get_weather_with_weatherapi(api_key, city_name)\n",
        "print(weather_info)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kqXbOXd3uAx",
        "outputId": "db3bc4b6-68a3-4ce7-c02f-68745e1dd8ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current weather in Las Vegas, Nevada, United States of America is Sunny with a temperature of 9.4°C that feels like 9.6°C. Humidity is at 44%. Wind speed is 3.8 mph.the local time is 2023-11-23 8:20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#traffic API\n",
        "\n",
        "import requests\n",
        "\n",
        "api_key = 'YOUR_API_KEY'  # Replace with your actual TomTom API key\n",
        "version_number = '1'  # Check the latest API version in the documentation\n",
        "\n",
        "# TomTom Traffic API endpoint example for traffic incidents\n",
        "traffic_incidents_endpoint = f\"https://api.tomtom.com/traffic/services/5/incidentDetails?bbox=4.8854592519716675%2C52.36934334773164%2C4.897883244144765%2C52.37496348620152&fields=%7Bincidents%7Btype%2Cgeometry%7Btype%2Ccoordinates%7D%2Cproperties%7BiconCategory%7D%7D%7D&language=en-GB&categoryFilter=0%2C1%2C2%2C3%2C4%2C5%2C6%2C7%2C8%2C9%2C10%2C11%2C14&timeValidityFilter=present&key=FY0suJKC0xfktJmHjnNOGLXRmSyvS6zi\"\n",
        "\n",
        "\n",
        "\n",
        "response = requests.get(traffic_incidents_endpoint, params=params)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    # Process the response if successful\n",
        "    traffic_data = response.json()\n",
        "    # Implement your logic to incorporate traffic_data into your language model\n",
        "    print(traffic_data)\n",
        "else:\n",
        "    print(f\"Error: {response.status_code}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ5W6eSFVP_n",
        "outputId": "52b1f960-e141-4c25-8e37-9ae8e739aa61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'incidents': [{'type': 'Feature', 'properties': {'iconCategory': 8}, 'geometry': {'type': 'LineString', 'coordinates': [[4.8869043181, 52.373369829], [4.8868144641, 52.3722794802]]}}, {'type': 'Feature', 'properties': {'iconCategory': 8}, 'geometry': {'type': 'LineString', 'coordinates': [[4.8893679271, 52.3715365312], [4.8897166142, 52.3715780851]]}}, {'type': 'Feature', 'properties': {'iconCategory': 8}, 'geometry': {'type': 'LineString', 'coordinates': [[4.8905708978, 52.3716625745], [4.8902865837, 52.371635759], [4.8897166142, 52.3715780851], [4.8893679271, 52.3715365312]]}}, {'type': 'Feature', 'properties': {'iconCategory': 6}, 'geometry': {'type': 'LineString', 'coordinates': [[4.8924296687, 52.3698788984], [4.8924739251, 52.3699499828], [4.8925704846, 52.3701484964], [4.8926348577, 52.3703295068], [4.8927394638, 52.3707090788], [4.8927609215, 52.3707935698], [4.892793108, 52.3708954603], [4.8928293178, 52.3710402868], [4.8928346822, 52.3710644415], [4.8928601632, 52.3711851639], [4.8928775976, 52.3713179121], [4.8928869853, 52.371393037], [4.8928655276, 52.3717202482], [4.8928521166, 52.3718221878]]}}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#schema of function, may be useful to use python functions in the model (not sure)\n",
        "from pydantic import create_model\n",
        "import inspect, json\n",
        "from inspect import Parameter\n",
        "\n",
        "\n",
        "\n",
        "def schema(f):\n",
        "    kw = {n:(o.annotation, ... if o.default==Parameter.empty else o.default)\n",
        "          for n,o in inspect.signature(f).parameters.items()}\n",
        "    s = create_model(f'Input for `{f.__name__}`', **kw).schema()\n",
        "    return dict(name=f.__name__, description=f.__doc__, parameters=s)"
      ],
      "metadata": {
        "id": "W8h9mVkgPDq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema(get_weather_with_weatherapi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chB2SS0nO5ew",
        "outputId": "f4985935-43c7-4c83-e0b5-4e034794db9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'get_weather_with_weatherapi',\n",
              " 'description': None,\n",
              " 'parameters': {'title': 'Input for `get_weather_with_weatherapi`',\n",
              "  'type': 'object',\n",
              "  'properties': {'api_key': {'title': 'Api Key', 'type': 'string'},\n",
              "   'city_name': {'title': 'City Name', 'type': 'string'}},\n",
              "  'required': ['api_key', 'city_name']}}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}